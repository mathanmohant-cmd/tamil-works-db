# Professor P. Pandiaraja's Word Segmentation Principles
## Summary for Database Import

Based on: http://tamilconcordance.in/Principles.html

---

## Key Principles for Our Parser

### 1. **Basic Word Separation**
- **Spaces separate words** - this is our primary delimiter
- Words are already properly segmented by Professor Pandiaraja
- We don't need complex Tamil NLP tokenization - the work is done!

### 2. **Special Characters**

#### **Underscore `_` - Compound Word Marker**
Indicates parts of a compound word that should be counted separately but are part of one semantic unit.

**Examples:**
- `рооропро┐ро░рпН_роХрпБро▒рпИ_роХро░рпБро╡ро┐` = рооропро┐ро░рпН + роХрпБро▒рпИ + роХро░рпБро╡ро┐ (hair-cutting tool)
- `роЪро┐ро▓рпН_рокрод_роЙрогро╡рпБ` = роЪро┐ро▓рпН + рокрод + роЙрогро╡рпБ (special food)
- `роЕро▒рпБ_роХро╛ро▓рпН_рокро▒ро╡рпИ` = роЕро▒рпБ + роХро╛ро▓рпН + рокро▒ро╡рпИ (six-legged bird)

**Database Strategy:**
```sql
-- Store in words table:
word_text = 'рооропро┐ро░рпН_роХрпБро▒рпИ_роХро░рпБро╡ро┐'
sandhi_split = 'рооропро┐ро░рпН + роХрпБро▒рпИ + роХро░рпБро╡ро┐'

-- Also create separate word entries for:
-- рооропро┐ро░рпН, роХрпБро▒рпИрпН, роХро░рпБро╡ро┐ (for search purposes)
```

#### **Hyphen `-` - Particle/Suffix Marker**
Indicates grammatical particles (роХроЯрпНроЯрпБро░рпБрокройрпН) that cannot be separated.

**Examples:**
- `ро╡ро┐роЯрпБроиро│рпН-рооройрпН-роХрпКро▓рпНро▓рпЛ` = ро╡ро┐роЯрпБроиро│рпН + particles
- `роЖро▒рпНро▒ро▓ро░рпН-рооройрпНройрпЗ` = роЖро▒рпНро▒ро▓ро░рпН + emphatic particle
- `роиро╛ро│рпН-родрпКро▒рпБроорпН` = роиро╛ро│рпН + distributive particle
- `роЪрпЖро▓рпНроХ-роОрой` = роЪрпЖро▓рпНроХ + quotative particle

**Database Strategy:**
```sql
-- Store as single word:
word_text = 'ро╡ро┐роЯрпБроиро│рпН-рооройрпН-роХрпКро▓рпНро▓рпЛ'
-- Can extract base later for advanced features
```

### 3. **What NOT to Separate**

#### Already kept together:
- **Case markers (ро╡рпЗро▒рпНро▒рпБроорпИ роЙро░рпБрокрпБроХро│рпН)**: роХрогрпНрогрпИ, роХрогрпНрогрпЛроЯрпБ, роХрогрпНрогро╛ро▓рпН
- **Tense markers**: ро╡роирпНродро╛ройрпН, ро╡ро░рпБроХро┐ро▒ро╛ройрпН
- **Compound words**: роиро▓рпНро▓рпЛро░рпН, рокрпЖро░ро┐ропрпЛро░рпН
- **Reduplication**: роКро░рпВро░рпН, ро╡ро┤ро┐ро╡ро┤ро┐, роорпЖро▓рпНроорпЖро▓

### 4. **Parsing Strategy for Our Database**

```python
def parse_line_to_words(line_text):
    """
    Parse Tamil line into words following Pandiaraja's principles
    """
    words = []
    position = 1

    # Split by space
    for token in line_text.split():
        # Clean punctuation if needed
        token = token.strip('.,;!?')

        if not token:
            continue

        # Handle compound words with underscore
        if '_' in token:
            # Store full compound
            words.append({
                'word_text': token,
                'word_position': position,
                'sandhi_split': token.replace('_', ' + '),
                'is_compound': True
            })

            # Also store component words for search
            components = token.split('_')
            for comp in components:
                words.append({
                    'word_text': comp,
                    'word_position': position,
                    'is_component': True,
                    'parent_compound': token
                })

        # Handle particles with hyphen
        elif '-' in token:
            # Store as single word with particle
            words.append({
                'word_text': token,
                'word_position': position,
                'has_particle': True
            })

        # Simple word
        else:
            words.append({
                'word_text': token,
                'word_position': position
            })

        position += 1

    return words
```

---

## Simplified Import Strategy

### Phase 1: Basic Import (NOW)
```python
# For each line:
1. Split by spaces
2. Store each space-separated token as a word
3. Keep _ and - as-is in word_text
4. Position = order in line
```

**Database columns to fill now:**
- `word_text` - exact token (with _ or - if present)
- `word_position` - 1, 2, 3...
- `line_id` - foreign key

**Leave NULL for now:**
- `word_root` тЭМ
- `word_type` тЭМ
- `sandhi_split` тЭМ (can extract from _ later)
- `meaning` тЭМ

### Phase 2: Enhanced (LATER)
```sql
-- Extract sandhi splits for compound words
UPDATE words
SET sandhi_split = REPLACE(word_text, '_', ' + ')
WHERE word_text LIKE '%_%';

-- Extract particles
UPDATE words
SET word_type = 'particle'
WHERE word_text LIKE '%-рооройрпН%'
   OR word_text LIKE '%-роХрпКро▓рпН%'
   OR word_text LIKE '%-родрпКро▒рпБроорпН%';

-- Add word roots (requires Tamil NLP)
-- Add POS tags (requires Tamil NLP)
-- Add meanings (requires dictionary)
```

---

## Example Parsing

### Input Line:
```
роХрогрпНрогрпИ-роХрпКро▓рпН рооропро┐ро░рпН_роХрпБро▒рпИ_роХро░рпБро╡ро┐ роХрпКрогрпНроЯрпБ роЪрпЖро▓рпНро▓рпБроорпН роиро╛ро│рпН-родрпКро▒рпБроорпН
```

### Output Words:
```python
[
    {'word_text': 'роХрогрпНрогрпИ-роХрпКро▓рпН', 'position': 1},
    {'word_text': 'рооропро┐ро░рпН_роХрпБро▒рпИ_роХро░рпБро╡ро┐', 'position': 2, 'sandhi_split': 'рооропро┐ро░рпН + роХрпБро▒рпИ + роХро░рпБро╡ро┐'},
    {'word_text': 'роХрпКрогрпНроЯрпБ', 'position': 3},
    {'word_text': 'роЪрпЖро▓рпНро▓рпБроорпН', 'position': 4},
    {'word_text': 'роиро╛ро│рпН-родрпКро▒рпБроорпН', 'position': 5}
]
```

### Database Inserts:
```sql
-- 5 word records
INSERT INTO words (line_id, word_position, word_text, sandhi_split) VALUES
(1, 1, 'роХрогрпНрогрпИ-роХрпКро▓рпН', NULL),
(1, 2, 'рооропро┐ро░рпН_роХрпБро▒рпИ_роХро░рпБро╡ро┐', 'рооропро┐ро░рпН + роХрпБро▒рпИ + роХро░рпБро╡ро┐'),
(1, 3, 'роХрпКрогрпНроЯрпБ', NULL),
(1, 4, 'роЪрпЖро▓рпНро▓рпБроорпН', NULL),
(1, 5, 'роиро╛ро│рпН-родрпКро▒рпБроорпН', NULL);
```

---

## Search Implications

### User searches for: "роХрогрпНрогрпИ"
Should match:
- тЬЕ роХрогрпНрогрпИ (exact)
- тЬЕ роХрогрпНрогрпИ-роХрпКро▓рпН (partial match with -kol particle)
- тЬЕ роХрогрпНрогрпИроХрпН (with case marker - if exists)

### User searches for: "роХрпБро▒рпИ"
Should match:
- тЬЕ роХрпБро▒рпИ (standalone word)
- тЬЕ рооропро┐ро░рпН_роХрпБро▒рпИ_роХро░рпБро╡ро┐ (compound word containing роХрпБро▒рпИ)

### Implementation:
```sql
-- Simple search (current)
SELECT * FROM word_details
WHERE word_text LIKE '%роХрпБро▒рпИ%';

-- Advanced search (later with _ split handling)
SELECT * FROM word_details
WHERE word_text = 'роХрпБро▒рпИ'
   OR word_text LIKE '%_роХрпБро▒рпИ%'
   OR word_text LIKE '%роХрпБро▒рпИ_%'
   OR word_text LIKE '%_роХрпБро▒рпИ_%';
```

---

## Summary

### тЬЕ What We Know:
1. **Space = word boundary** (primary rule)
2. **_ = compound parts** (store split in sandhi_split)
3. **- = particles** (keep together, mark for later analysis)
4. **No further tokenization needed** - Professor did the hard work!

### ЁЯЪА What We'll Do:
1. **Split by spaces only**
2. **Store word_text exactly as-is**
3. **Extract sandhi_split from _ for compounds**
4. **Let search handle partial matches**

### ЁЯОп Result:
- **Simple parser** (30-50 lines of Python)
- **Fast import** (thousands of words per second)
- **Accurate data** (respects scholarly segmentation)
- **Search ready** (all words indexed and searchable)

---

## Ready to Code!

With these principles, we can now create:
1. тЬЕ Simple, robust parser
2. тЬЕ Fast bulk import
3. тЬЕ Immediate search functionality
4. тЬЕ Foundation for advanced features later

**Next step:** Create the parser scripts!
